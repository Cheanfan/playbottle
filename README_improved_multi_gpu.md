# 改进版多GPU图片描述生成脚本

这个脚本是基于你原始代码改造的多GPU并行版本，可以将数据平均分成8份并在8张GPU上分别处理。

## 主要特性

### 🚀 核心改进
- **数据均匀分割**: 自动将所有任务平均分配给8张GPU
- **真正并行处理**: 每个GPU独立处理自己的数据块，无需等待
- **内存优化**: 每个GPU只加载一次模型，定期清理内存
- **断点续传**: 自动跳过已处理的图片，支持中断后继续
- **实时监控**: 显示总体进度、处理速度和GPU利用率

### 📊 性能优势
- **8倍理论加速**: 8张GPU并行处理
- **高效内存管理**: 避免GPU内存溢出
- **智能任务分配**: 处理任务数不是8的倍数时也能均匀分配

## 文件结构要求

确保你的目录结构如下：
```
your_project/
├── jsons/                    # 包含所有JSON配置文件
├── json_detail/             # 包含详细JSON文件  
├── shape_descriptions/      # 输出目录（自动创建）
└── improved_multi_gpu_caption.py  # 脚本文件
```

数据集图片应该位于：`/root/dataset/raw/`

## 安装依赖

```bash
pip install torch torchvision
pip install transformers
pip install datasets
pip install tqdm
pip install pillow
pip install qwen-vl-utils
```

## 使用方法

### 基本使用
```bash
python improved_multi_gpu_caption.py
```

### 配置参数

在脚本的 `main()` 函数中可以修改以下参数：

```python
def main():
    # 配置参数
    NUM_GPUS = 8  # GPU数量（可以根据你的硬件调整）
    MODEL_NAME = "HuggingFaceM4/idefics2-8b"  # 模型名称
```

## 工作原理

### 1. 任务准备阶段
- 扫描 `./jsons/` 目录下的所有JSON文件
- 读取对应的 `./json_detail/` 文件获取详细信息
- 过滤掉 `TextElement` 和 `ImageElement` 类型
- 检查输出文件是否已存在，跳过已处理的任务

### 2. 数据分割阶段
```
假设有1000个任务，8张GPU：
- GPU 0: 任务 0-124 (125个任务)
- GPU 1: 任务 125-249 (125个任务)  
- GPU 2: 任务 250-374 (125个任务)
- GPU 3: 任务 375-499 (125个任务)
- GPU 4: 任务 500-624 (125个任务)
- GPU 5: 任务 625-749 (125个任务)
- GPU 6: 任务 750-874 (125个任务)
- GPU 7: 任务 875-999 (125个任务)
```

### 3. 并行处理阶段
每个GPU进程：
1. 加载模型到指定GPU设备
2. 独立处理分配给它的任务块
3. 生成图片描述并保存到文件
4. 定期清理GPU内存

### 4. 结果收集阶段
- 实时监控所有GPU的处理进度
- 统计成功/失败的处理数量
- 显示总体处理速度和GPU利用率

## 输出格式

每张图片的描述会保存为单独的文本文件：
```
./shape_descriptions/image_filename.png.txt
```

文件内容为图片的简短描述（30词以内）。

## 性能监控

脚本运行时会显示：
- 总体进度条
- 实时处理速度（图片/秒）
- GPU数量和利用率
- 成功/失败统计

示例输出：
```
配置信息:
- GPU数量: 8
- 模型: HuggingFaceM4/idefics2-8b
- 数据将平均分配到各个GPU上并行处理

准备任务列表...
扫描JSON文件: 100%|██████████| 1000/1000 [00:05<00:00, 180.23it/s]
总共需要处理 5000 张图片

GPU 0: 分配 625 个任务 (索引 0-624)
GPU 1: 分配 625 个任务 (索引 625-1249)
GPU 2: 分配 625 个任务 (索引 1250-1874)
...

开始处理 5000 张图片...
总体进度: 45%|████▌     | 2250/5000 [05:30<06:45, 6.8 img/s, speed=6.80 img/s, GPUs=8]
```

## 故障处理

### 常见问题

1. **GPU内存不足**
   - 减少 `NUM_GPUS` 数量
   - 脚本已包含内存清理机制

2. **某个GPU处理失败**
   - 其他GPU会继续工作
   - 失败的任务会在日志中显示

3. **中断后继续处理**
   - 重新运行脚本即可
   - 已处理的文件会自动跳过

### 监控GPU使用情况
```bash
# 实时监控GPU状态
nvidia-smi -l 1

# 查看GPU内存使用
gpustat -i 1
```

## 与原始代码的对比

| 特性 | 原始代码 | 改进版多GPU |
|------|----------|-------------|
| GPU利用 | 单GPU | 8GPU并行 |
| 处理速度 | 1x | ~8x |
| 内存管理 | 基础 | 优化清理 |
| 断点续传 | 无 | 支持 |
| 进度监控 | 简单 | 详细统计 |
| 错误处理 | 基础 | 健壮机制 |

## 注意事项

1. **硬件要求**: 确保有8张GPU且每张GPU有足够内存加载模型
2. **路径配置**: 确认图片路径 `/root/dataset/raw/` 正确
3. **文件权限**: 确保有写入 `./shape_descriptions/` 目录的权限
4. **进程管理**: 使用 `Ctrl+C` 可以安全中断脚本

## 扩展性

可以轻松调整为使用不同数量的GPU：
```python
NUM_GPUS = 4  # 使用4张GPU
NUM_GPUS = 16 # 使用16张GPU（如果有的话）
```

脚本会自动调整数据分割策略。 